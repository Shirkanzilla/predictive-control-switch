{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdaa2e2",
   "metadata": {},
   "source": [
    "# Methods for loading a trained agent provided by Markel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448bd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from omnisafe.common import Normalizer\n",
    "from omnisafe.envs.wrapper import ActionRepeat, ActionScale, ObsNormalize, TimeLimit\n",
    "from omnisafe.models.actor_critic.constraint_actor_q_critic import ConstraintActorQCritic\n",
    "from omnisafe.utils.config import Config\n",
    "from omnisafe.envs.core import CMDP, make\n",
    "from omnisafe.algorithms.model_based.base.ensemble import EnsembleDynamicsModel\n",
    "from omnisafe.models.actor import ActorBuilder\n",
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "\n",
    "def _load_model_and_env(\n",
    "    save_dir: str,\n",
    "    model_name: str,\n",
    "    cfgs: Config,\n",
    "    env_kwargs: Dict[str, Any],\n",
    ") -> None:\n",
    "    \"\"\"Load the model from the save directory.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): Directory where the model is saved.\n",
    "        model_name (str): Name of the model.\n",
    "        env_kwargs (dict[str, Any]): Keyword arguments for the environment.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the model is not found.\n",
    "    \"\"\"\n",
    "    # load the saved model\n",
    "    model_path = os.path.join(save_dir, 'torch_save', model_name)\n",
    "    try:\n",
    "        model_params = torch.load(model_path)\n",
    "    except FileNotFoundError as error:\n",
    "        raise FileNotFoundError('The model is not found in the save directory.') from error\n",
    "\n",
    "    # load the environment\n",
    "    env = make(**env_kwargs)\n",
    "\n",
    "    observation_space = env.observation_space\n",
    "    action_space = env.action_space\n",
    "    if 'Saute' in cfgs['algo'] or 'Simmer' in cfgs['algo']:\n",
    "        safety_budget = (\n",
    "            cfgs.algo_cfgs.safety_budget\n",
    "            * (1 - cfgs.algo_cfgs.saute_gamma**cfgs.algo_cfgs.max_ep_len)\n",
    "            / (1 - cfgs.algo_cfgs.saute_gamma)\n",
    "            / cfgs.algo_cfgs.max_ep_len\n",
    "            * torch.ones(1)\n",
    "        )\n",
    "    assert isinstance(observation_space, Box), 'The observation space must be Box.'\n",
    "    assert isinstance(action_space, Box), 'The action space must be Box.'\n",
    "\n",
    "    if cfgs['algo_cfgs']['obs_normalize']:\n",
    "        obs_normalizer = Normalizer(shape=observation_space.shape, clip=5)\n",
    "        obs_normalizer.load_state_dict(model_params['obs_normalizer'])\n",
    "        env = ObsNormalize(env, device=torch.device('cpu'), norm=obs_normalizer)\n",
    "    if env.need_time_limit_wrapper:\n",
    "        env = TimeLimit(env, device=torch.device('cpu'), time_limit=1000)\n",
    "    env = ActionScale(env, device=torch.device('cpu'), low=-1.0, high=1.0)\n",
    "\n",
    "    if hasattr(cfgs['algo_cfgs'], 'action_repeat'):\n",
    "        env = ActionRepeat(\n",
    "            env,\n",
    "            device=torch.device('cpu'),\n",
    "            times=cfgs['algo_cfgs']['action_repeat'],\n",
    "        )\n",
    "    if hasattr(cfgs, 'algo') and cfgs['algo'] in [\n",
    "        'LOOP',\n",
    "        'SafeLOOP',\n",
    "        'PETS',\n",
    "        'CAPPETS',\n",
    "        'RCEPETS',\n",
    "        'CCEPETS',\n",
    "    ]:\n",
    "        dynamics_state_space = (\n",
    "            env.coordinate_observation_space\n",
    "            if env.coordinate_observation_space is not None\n",
    "            else env.observation_space\n",
    "        )\n",
    "        assert env.action_space is not None and isinstance(\n",
    "            env.action_space.shape,\n",
    "            tuple,\n",
    "        )\n",
    "        if isinstance(env.action_space, Box):\n",
    "            action_space = env.action_space\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if cfgs['algo'] in ['LOOP', 'SafeLOOP']:\n",
    "            actor_critic = ConstraintActorQCritic(\n",
    "                obs_space=dynamics_state_space,\n",
    "                act_space=action_space,\n",
    "                model_cfgs=cfgs.model_cfgs,\n",
    "                epochs=1,\n",
    "            )\n",
    "        if actor_critic is not None:\n",
    "            actor_critic.load_state_dict(model_params['actor_critic'])\n",
    "            actor_critic.to('cpu')\n",
    "        dynamics = EnsembleDynamicsModel(\n",
    "            model_cfgs=cfgs.dynamics_cfgs,\n",
    "            device=torch.device('cpu'),\n",
    "            state_shape=dynamics_state_space.shape,\n",
    "            action_shape=action_space.shape,\n",
    "            actor_critic=actor_critic,\n",
    "            rew_func=None,\n",
    "            cost_func=env.get_cost_from_obs_tensor,\n",
    "            terminal_func=None,\n",
    "        )\n",
    "        dynamics.ensemble_model.load_state_dict(model_params['dynamics'])\n",
    "        dynamics.ensemble_model.to('cpu')\n",
    "        if cfgs['algo'] in ['CCEPETS', 'RCEPETS', 'SafeLOOP']:\n",
    "            algo_to_planner = {\n",
    "                'CCEPETS': (\n",
    "                    'CCEPlanner',\n",
    "                    {'cost_limit': cfgs['algo_cfgs']['cost_limit']},\n",
    "                ),\n",
    "                'RCEPETS': (\n",
    "                    'RCEPlanner',\n",
    "                    {'cost_limit': cfgs['algo_cfgs']['cost_limit']},\n",
    "                ),\n",
    "                'SafeLOOP': (\n",
    "                    'SafeARCPlanner',\n",
    "                    {\n",
    "                        'cost_limit': cfgs['algo_cfgs']['cost_limit'],\n",
    "                        'actor_critic': actor_critic,\n",
    "                    },\n",
    "                ),\n",
    "            }\n",
    "        elif cfgs['algo'] in ['PETS', 'LOOP']:\n",
    "            algo_to_planner = {\n",
    "                'PETS': ('CEMPlanner', {}),\n",
    "                'LOOP': ('ARCPlanner', {'actor_critic': actor_critic}),\n",
    "            }\n",
    "        elif cfgs['algo'] in ['CAPPETS']:\n",
    "            lagrange: torch.nn.Parameter = torch.nn.Parameter(\n",
    "                model_params['lagrangian_multiplier'].to('cpu'),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "            algo_to_planner = {\n",
    "                'CAPPETS': (\n",
    "                    'CAPPlanner',\n",
    "                    {\n",
    "                        'cost_limit': cfgs['lagrange_cfgs']['cost_limit'],\n",
    "                        'lagrange': lagrange,\n",
    "                    },\n",
    "                ),\n",
    "            }\n",
    "        planner_name = algo_to_planner[cfgs['algo']][0]\n",
    "        planner_special_cfgs = algo_to_planner[cfgs['algo']][1]\n",
    "        planner_cls = globals()[f'{planner_name}']\n",
    "        planner = planner_cls(\n",
    "            dynamics=dynamics,\n",
    "            planner_cfgs=cfgs.planner_cfgs,\n",
    "            gamma=float(cfgs.algo_cfgs.gamma),\n",
    "            cost_gamma=float(cfgs.algo_cfgs.cost_gamma),\n",
    "            dynamics_state_shape=dynamics_state_space.shape,\n",
    "            action_shape=action_space.shape,\n",
    "            action_max=1.0,\n",
    "            action_min=-1.0,\n",
    "            device='cpu',\n",
    "            **planner_special_cfgs,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if 'Saute' in cfgs['algo'] or 'Simmer' in cfgs['algo']:\n",
    "            observation_space = Box(\n",
    "                low=np.hstack((observation_space.low, -np.inf)),\n",
    "                high=np.hstack((observation_space.high, np.inf)),\n",
    "                shape=(observation_space.shape[0] + 1,),\n",
    "            )\n",
    "        actor_type = cfgs['model_cfgs']['actor_type']\n",
    "        pi_cfg = cfgs['model_cfgs']['actor']\n",
    "        weight_initialization_mode = cfgs['model_cfgs']['weight_initialization_mode']\n",
    "        actor_builder = ActorBuilder(\n",
    "            obs_space=observation_space,\n",
    "            act_space=action_space,\n",
    "            hidden_sizes=pi_cfg['hidden_sizes'],\n",
    "            activation=pi_cfg['activation'],\n",
    "            weight_initialization_mode=weight_initialization_mode,\n",
    "        )\n",
    "        actor = actor_builder.build_actor(actor_type)\n",
    "        actor.load_state_dict(model_params['pi'])\n",
    "\n",
    "    return env, actor\n",
    "\n",
    "\n",
    "def _load_cfgs(save_dir):\n",
    "    cfg_path = os.path.join(save_dir, 'config.json')\n",
    "    try:\n",
    "        with open(cfg_path, encoding='utf-8') as file:\n",
    "            kwargs = json.load(file)\n",
    "    except FileNotFoundError as error:\n",
    "        raise FileNotFoundError(\n",
    "            f'The config file is not found in the save directory{save_dir}.',\n",
    "        ) from error\n",
    "    return Config.dict2config(kwargs)\n",
    "\n",
    "\n",
    "# LOG_DIR should contain two things:\n",
    "# 1. config.json\n",
    "# 2. torch_save/{model_name}\n",
    "#\n",
    "# model_name usually looks like 'epoch-500.pt'\n",
    "def load_guide(save_dir, model_name) -> Tuple[CMDP, ConstraintActorQCritic]:\n",
    "    cfgs = _load_cfgs(save_dir)\n",
    "\n",
    "    env_kwargs = {\n",
    "        'env_id': cfgs['env_id'],\n",
    "        'num_envs': 1,\n",
    "    }\n",
    "\n",
    "    env, actor = _load_model_and_env(save_dir, model_name, cfgs, env_kwargs)\n",
    "    return env, actor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171f0d8",
   "metadata": {},
   "source": [
    "# Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6ac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnisafe.models.actor import GaussianLearningActor\n",
    "import safety_gymnasium\n",
    "import torch\n",
    "\n",
    "env = safety_gymnasium.make('SafetyPointGoal1-v0', max_episode_steps=1000)\n",
    "\n",
    "def create_random_agent(env, hidden_layers=[255,255,255,255], activation='relu', weight_initialization_mode='orthogonal'):\n",
    "    obs_space = env.observation_space\n",
    "    act_space = env.action_space\n",
    "    return GaussianLearningActor(obs_space, act_space, hidden_layers, activation=activation, weight_initialization_mode=weight_initialization_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75645ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Dict('accelerometer': Box(-inf, inf, (3,), float64), 'velocimeter': Box(-inf, inf, (3,), float64), 'gyro': Box(-inf, inf, (3,), float64), 'magnetometer': Box(-inf, inf, (3,), float64), 'goal_lidar': Box(0.0, 1.0, (16,), float64), 'hazards_lidar': Box(0.0, 1.0, (16,), float64), 'vases_lidar': Box(0.0, 1.0, (16,), float64)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.obs_space_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece55959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (2,), float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_trajectory(env, agent, safe_agent, min_rand_steps=100, max_rand_steps=400, cost_window=200, deterministic=True):\n",
    "    observation, info = env.reset()\n",
    "    episode_over = False\n",
    "    is_sampling = False\n",
    "    sampled_cost = 0\n",
    "    sampling_step = 0\n",
    "    agent_instance_for_pos = env.unwrapped.__getattribute__(\"task\").agent\n",
    "    data = []\n",
    "    labels = []\n",
    "    # get a random number for the amount of steps the random agent should take before a sample is created\n",
    "    num_steps = np.random.randint(min_rand_steps, max_rand_steps)\n",
    "    # gather data\n",
    "    for i in range(num_steps):\n",
    "        # Discard trajectory if the agent moves out of the checkered 7x7 space, coordinates were tested manually\n",
    "        if abs(agent_instance_for_pos.pos[0]) >= 3.5 or abs(agent_instance_for_pos.pos[1]) >= 3.5: \n",
    "            break\n",
    "        obs_tensor = torch.from_numpy(observation).float()\n",
    "        action = agent.predict(obs_tensor, deterministic=deterministic).detach().numpy()\n",
    "        if i == num_steps - 1:\n",
    "            data.append(np.append(observation, action)) \n",
    "        observation, reward, cost, terminated, truncated, info = env.step(action)\n",
    "        episode_over = terminated or truncated\n",
    "        if episode_over:\n",
    "            break\n",
    "    if not episode_over:\n",
    "        # sample with the pre trained agent\n",
    "        for i in range(cost_window):\n",
    "            obs_tensor = torch.from_numpy(observation).float()\n",
    "            action = safe_agent.predict(obs_tensor, deterministic=deterministic).detach().numpy()\n",
    "            observation, reward, cost, terminated, truncated, info = env.step(action)\n",
    "            episode_over = terminated or truncated\n",
    "            sampled_cost += cost\n",
    "            sampling_step += 1\n",
    "            if episode_over or i == cost_window - 1:\n",
    "                labels.append(sampled_cost)\n",
    "                break\n",
    "    if len(labels) == 0:\n",
    "        # If episode ended before sampling could happen, return an empty data and labels array\n",
    "        # More of a safety measure, probably obsolete\n",
    "        data = []\n",
    "    if len(data) == 0:\n",
    "        labels = []\n",
    "    env.close()\n",
    "    # assertion to make sure every data point has a label\n",
    "    print(len(data), len(labels))\n",
    "    assert len(data) == len(labels)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9818047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_968/1383116929.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_params = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# load my saved trained agent\n",
    "safe_agent = load_guide(\"../runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2025-05-13-17-51-08\", \"epoch-50.pt\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8497760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = run_trajectory(env, create_random_agent(env), safe_agent)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1fffc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f6b1075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 62)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca182c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844dddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_dataset(env, safe_agent, amount=1000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for _ in tqdm(range(amount), desc=\"Generating data points\", unit=\" sample \"):\n",
    "        data_i = []\n",
    "        while len(data_i) == 0: # Ensure that a sample is generated\n",
    "            data_i, labels_i = run_trajectory(env, create_random_agent(env), safe_agent)\n",
    "        data.append(data_i)\n",
    "        labels.append(labels_i)\n",
    "    return np.concatenate(data, axis=0)[:amount], np.concatenate(labels, axis=0)[:amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa23b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data points:   0%|          | 0/10000 [00:00<?, ? sample /s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data, labels \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 9\u001b[0m, in \u001b[0;36mgenerate_dataset\u001b[0;34m(env, safe_agent, amount)\u001b[0m\n\u001b[1;32m      7\u001b[0m data_i \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_i) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Ensure that a sample is generated\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     data_i, labels_i \u001b[38;5;241m=\u001b[39m \u001b[43mrun_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_random_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m data\u001b[38;5;241m.\u001b[39mappend(data_i)\n\u001b[1;32m     11\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(labels_i)\n",
      "Cell \u001b[0;32mIn[50], line 46\u001b[0m, in \u001b[0;36mrun_trajectory\u001b[0;34m(env, agent, safe_agent, min_rand_steps, max_rand_steps, cost_window, deterministic)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# assertion to make sure every data point has a label\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(labels))\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data), np\u001b[38;5;241m.\u001b[39marray(labels)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data, labels = generate_dataset(env, safe_agent, amount=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e063f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.85013843,   0.09889716,   9.81      , ...,   0.        ,\n",
       "          0.51997632,   1.10723567],\n",
       "       [  2.18100397,  11.70111903,   9.81      , ...,   0.        ,\n",
       "          0.49840754,  -1.83509505],\n",
       "       [ -4.60043508,  -9.89569702,   9.81      , ...,   0.        ,\n",
       "         -0.20032974,   0.43169472],\n",
       "       ...,\n",
       "       [ -3.24858488, -11.52092151,   9.81      , ...,   0.        ,\n",
       "         -0.18175644,   0.15351345],\n",
       "       [  0.36310884,   0.23373699,   9.81      , ...,   0.        ,\n",
       "          0.82411647,   1.38031697],\n",
       "       [  2.24830268,   0.29231609,   9.81      , ...,   0.        ,\n",
       "          0.50413424,   0.66061491]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "42dcdd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 62)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a61ad28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7962301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455af4aa",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset for better NN performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17f4ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/user/bachelor/RL/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/user/bachelor/RL/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: pandas in /home/user/bachelor/RL/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/bachelor/RL/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn scipy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06585e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_column_names = ['accelerometer0', 'accelerometer1', 'accelerometer2', 'velocimeter0', 'velocimeter1', 'velocimeter2', 'gyro0', 'gyro1', 'gyro2', 'magnetometer0', 'magnetometer1', 'magnetometer2']\n",
    "for key in ['goal_lidar', 'hazards_lidar', 'vases_lidar']:\n",
    "    for i in range(16):\n",
    "        obs_column_names.append(key+str(i))\n",
    "obs_column_names.append(\"action0\")\n",
    "obs_column_names.append(\"action1\")\n",
    "len(obs_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1fcfd790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "      <th>exp_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.859485</td>\n",
       "      <td>-6.547374</td>\n",
       "      <td>9.81</td>\n",
       "      <td>-0.002183</td>\n",
       "      <td>-0.022451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.187039</td>\n",
       "      <td>0.439323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048732</td>\n",
       "      <td>0.58323</td>\n",
       "      <td>0.534497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.308633</td>\n",
       "      <td>0.632612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.285026</td>\n",
       "      <td>15.194056</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.221309</td>\n",
       "      <td>0.207020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.295281</td>\n",
       "      <td>-0.168696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.787477</td>\n",
       "      <td>-1.150739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.982068</td>\n",
       "      <td>-0.473029</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.552082</td>\n",
       "      <td>-0.056404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.837879</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.468978</td>\n",
       "      <td>0.762941</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.987091</td>\n",
       "      <td>-3.815060</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.504868</td>\n",
       "      <td>-0.097781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.895468</td>\n",
       "      <td>0.423378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366803</td>\n",
       "      <td>-0.409778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.688365</td>\n",
       "      <td>0.278680</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.707879</td>\n",
       "      <td>0.046088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.897179</td>\n",
       "      <td>0.450792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.873569</td>\n",
       "      <td>-0.257621</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer0  accelerometer1  accelerometer2  velocimeter0  velocimeter1  \\\n",
       "0       -2.859485       -6.547374            9.81     -0.002183     -0.022451   \n",
       "1       -3.285026       15.194056            9.81      0.221309      0.207020   \n",
       "2        1.982068       -0.473029            9.81      0.552082     -0.056404   \n",
       "3        1.987091       -3.815060            9.81      0.504868     -0.097781   \n",
       "4        1.688365        0.278680            9.81      0.707879      0.046088   \n",
       "\n",
       "   velocimeter2  gyro0  gyro1     gyro2  magnetometer0  ...  vases_lidar9  \\\n",
       "0           0.0    0.0    0.0  1.187039       0.439323  ...           0.0   \n",
       "1           0.0    0.0    0.0  1.295281      -0.168696  ...           0.0   \n",
       "2           0.0    0.0    0.0  2.837879      -0.003965  ...           0.0   \n",
       "3           0.0    0.0    0.0  1.895468       0.423378  ...           0.0   \n",
       "4           0.0   -0.0    0.0 -2.897179       0.450792  ...           0.0   \n",
       "\n",
       "   vases_lidar10  vases_lidar11  vases_lidar12  vases_lidar13  vases_lidar14  \\\n",
       "0            0.0       0.048732        0.58323       0.534497            0.0   \n",
       "1            0.0       0.000000        0.00000       0.000000            0.0   \n",
       "2            0.0       0.000000        0.00000       0.000000            0.0   \n",
       "3            0.0       0.000000        0.00000       0.000000            0.0   \n",
       "4            0.0       0.000000        0.00000       0.000000            0.0   \n",
       "\n",
       "   vases_lidar15   action0   action1  exp_cost  \n",
       "0            0.0 -0.308633  0.632612       0.0  \n",
       "1            0.0  0.787477 -1.150739       0.0  \n",
       "2            0.0  1.468978  0.762941       0.0  \n",
       "3            0.0  0.366803 -0.409778       0.0  \n",
       "4            0.0  0.873569 -0.257621       0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=data, columns=obs_column_names)\n",
    "df['exp_cost'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "569467b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the create dataset in a pickle file\n",
    "df.to_pickle(\"SafetyPointGoal1Dataset0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b30392b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "      <th>exp_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.215973</td>\n",
       "      <td>0.208202</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.381894</td>\n",
       "      <td>-0.124796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688522</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030880</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>0.019791</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.208537</td>\n",
       "      <td>0.73690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.663695</td>\n",
       "      <td>7.699414</td>\n",
       "      <td>1.494856e-15</td>\n",
       "      <td>0.249333</td>\n",
       "      <td>0.164913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.961190</td>\n",
       "      <td>0.354208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117286</td>\n",
       "      <td>0.114021</td>\n",
       "      <td>0.106218</td>\n",
       "      <td>0.094793</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>0.621430</td>\n",
       "      <td>0.845010</td>\n",
       "      <td>5.49528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.319843</td>\n",
       "      <td>-18.154482</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>-1.264663</td>\n",
       "      <td>-0.975777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.998426</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.362725</td>\n",
       "      <td>-1.995620</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.135914</td>\n",
       "      <td>-5.502001</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.233487</td>\n",
       "      <td>-0.172205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.411241</td>\n",
       "      <td>-0.320050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.382356</td>\n",
       "      <td>-0.022300</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.815366</td>\n",
       "      <td>0.359430</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.387127</td>\n",
       "      <td>-0.100180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.239270</td>\n",
       "      <td>0.072442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464822</td>\n",
       "      <td>0.445041</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.266183</td>\n",
       "      <td>1.782016</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.543069</td>\n",
       "      <td>-0.038952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.161658</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750187</td>\n",
       "      <td>0.709381</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.499027</td>\n",
       "      <td>18.905644</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>1.464998</td>\n",
       "      <td>0.733211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.024529</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931661</td>\n",
       "      <td>0.932327</td>\n",
       "      <td>0.932784</td>\n",
       "      <td>0.932326</td>\n",
       "      <td>0.922131</td>\n",
       "      <td>0.922730</td>\n",
       "      <td>0.914572</td>\n",
       "      <td>2.151439</td>\n",
       "      <td>2.642204</td>\n",
       "      <td>127.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accelerometer0  accelerometer1  accelerometer2  velocimeter0  \\\n",
       "count    10000.000000    10000.000000    1.000000e+04  10000.000000   \n",
       "mean         0.215973        0.208202    9.810000e+00      0.381894   \n",
       "std          2.663695        7.699414    1.494856e-15      0.249333   \n",
       "min         -5.319843      -18.154482    9.810000e+00     -1.264663   \n",
       "25%         -3.135914       -5.502001    9.810000e+00      0.233487   \n",
       "50%          1.815366        0.359430    9.810000e+00      0.387127   \n",
       "75%          2.266183        1.782016    9.810000e+00      0.543069   \n",
       "max          5.499027       18.905644    9.810000e+00      1.464998   \n",
       "\n",
       "       velocimeter1  velocimeter2    gyro0    gyro1         gyro2  \\\n",
       "count  10000.000000       10000.0  10000.0  10000.0  10000.000000   \n",
       "mean      -0.124796           0.0      0.0      0.0      0.688522   \n",
       "std        0.164913           0.0      0.0      0.0      1.961190   \n",
       "min       -0.975777           0.0      0.0      0.0     -2.998426   \n",
       "25%       -0.172205           0.0      0.0      0.0     -0.411241   \n",
       "50%       -0.100180           0.0      0.0      0.0      1.239270   \n",
       "75%       -0.038952           0.0      0.0      0.0      2.161658   \n",
       "max        0.733211           0.0      0.0      0.0      3.024529   \n",
       "\n",
       "       magnetometer0  ...  vases_lidar9  vases_lidar10  vases_lidar11  \\\n",
       "count   10000.000000  ...  10000.000000   10000.000000   10000.000000   \n",
       "mean        0.033000  ...      0.030880       0.027600       0.023616   \n",
       "std         0.354208  ...      0.117286       0.114021       0.106218   \n",
       "min        -0.500000  ...      0.000000       0.000000       0.000000   \n",
       "25%        -0.320050  ...      0.000000       0.000000       0.000000   \n",
       "50%         0.072442  ...      0.000000       0.000000       0.000000   \n",
       "75%         0.384359  ...      0.000000       0.000000       0.000000   \n",
       "max         0.500000  ...      0.931661       0.932327       0.932784   \n",
       "\n",
       "       vases_lidar12  vases_lidar13  vases_lidar14  vases_lidar15  \\\n",
       "count   10000.000000   10000.000000   10000.000000   10000.000000   \n",
       "mean        0.019791       0.018726       0.017807       0.016469   \n",
       "std         0.094793       0.093052       0.090702       0.082850   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         0.932326       0.922131       0.922730       0.914572   \n",
       "\n",
       "            action0       action1     exp_cost  \n",
       "count  10000.000000  10000.000000  10000.00000  \n",
       "mean       0.246060      0.208537      0.73690  \n",
       "std        0.621430      0.845010      5.49528  \n",
       "min       -1.362725     -1.995620      0.00000  \n",
       "25%       -0.382356     -0.022300      0.00000  \n",
       "50%        0.464822      0.445041      0.00000  \n",
       "75%        0.750187      0.709381      0.00000  \n",
       "max        2.151439      2.642204    127.00000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d695970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset into data and label again\n",
    "X = df.drop(columns=[\"exp_cost\"])\n",
    "y = df.exp_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "784054d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar8</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227414</td>\n",
       "      <td>0.313197</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.462505</td>\n",
       "      <td>0.557831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694919</td>\n",
       "      <td>0.939323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052244</td>\n",
       "      <td>0.625564</td>\n",
       "      <td>0.579633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299955</td>\n",
       "      <td>0.566695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188080</td>\n",
       "      <td>0.899850</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.544380</td>\n",
       "      <td>0.692104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712890</td>\n",
       "      <td>0.331304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611867</td>\n",
       "      <td>0.182172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674924</td>\n",
       "      <td>0.477102</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.665557</td>\n",
       "      <td>0.537963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969010</td>\n",
       "      <td>0.496035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.594796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675388</td>\n",
       "      <td>0.386923</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.648260</td>\n",
       "      <td>0.513752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.923378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492159</td>\n",
       "      <td>0.341937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647776</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.950792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636366</td>\n",
       "      <td>0.374744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer0  accelerometer1  accelerometer2  velocimeter0  velocimeter1  \\\n",
       "0        0.227414        0.313197            1.00      0.462505      0.557831   \n",
       "1        0.188080        0.899850            1.00      0.544380      0.692104   \n",
       "2        0.674924        0.477102            0.50      0.665557      0.537963   \n",
       "3        0.675388        0.386923            1.00      0.648260      0.513752   \n",
       "4        0.647776        0.497385            0.25      0.722633      0.597936   \n",
       "\n",
       "   velocimeter2  gyro0  gyro1     gyro2  magnetometer0  ...  vases_lidar8  \\\n",
       "0           0.0    0.0    0.0  0.694919       0.939323  ...           0.0   \n",
       "1           0.0    0.0    0.0  0.712890       0.331304  ...           0.0   \n",
       "2           0.0    0.0    0.0  0.969010       0.496035  ...           0.0   \n",
       "3           0.0    0.0    0.0  0.812540       0.923378  ...           0.0   \n",
       "4           0.0    0.0    0.0  0.016810       0.950792  ...           0.0   \n",
       "\n",
       "   vases_lidar9  vases_lidar10  vases_lidar11  vases_lidar12  vases_lidar13  \\\n",
       "0           0.0            0.0       0.052244       0.625564       0.579633   \n",
       "1           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "2           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "3           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "4           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "\n",
       "   vases_lidar14  vases_lidar15   action0   action1  \n",
       "0            0.0            0.0  0.299955  0.566695  \n",
       "1            0.0            0.0  0.611867  0.182172  \n",
       "2            0.0            0.0  0.805797  0.594796  \n",
       "3            0.0            0.0  0.492159  0.341937  \n",
       "4            0.0            0.0  0.636366  0.374744  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler((0,1))\n",
    "scaled = scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled, columns=obs_column_names)\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "def8a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into train, test and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3b709da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 62)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6022018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 62)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "833deaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 62)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5f1131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert dataset into a TensorDataset\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train.values.astype(np.float32)), torch.from_numpy(y_train.values.astype(np.float32)))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(X_validate.values.astype(np.float32)), torch.from_numpy(y_validate.values.astype(np.float32)))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test.values.astype(np.float32)), torch.from_numpy(y_test.values.astype(np.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6fa2a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Putting data into dataloaders for PyTorch\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380a50",
   "metadata": {},
   "source": [
    "# Building a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "359125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExpectedCostNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpectedCostNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(62, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6f2c7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44c476ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpectedCostNN(\n",
      "  (fc1): Linear(in_features=62, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ExpectedCostNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e230bc6",
   "metadata": {},
   "source": [
    "# Training a neural network on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f536ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze()\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02b46771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted to regression problem from original code https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c9b6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.031250  [   64/ 6400]\n",
      "loss: 151.093750  [  704/ 6400]\n",
      "loss: 1.593750  [ 1344/ 6400]\n",
      "loss: 45.562500  [ 1984/ 6400]\n",
      "loss: 0.062500  [ 2624/ 6400]\n",
      "loss: 1.296875  [ 3264/ 6400]\n",
      "loss: 30.078125  [ 3904/ 6400]\n",
      "loss: 25.765625  [ 4544/ 6400]\n",
      "loss: 16.000000  [ 5184/ 6400]\n",
      "loss: 48.421875  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.500000  [   64/ 6400]\n",
      "loss: 1.468750  [  704/ 6400]\n",
      "loss: 22.390625  [ 1344/ 6400]\n",
      "loss: 29.328125  [ 1984/ 6400]\n",
      "loss: 8.984375  [ 2624/ 6400]\n",
      "loss: 18.656250  [ 3264/ 6400]\n",
      "loss: 111.781250  [ 3904/ 6400]\n",
      "loss: 0.015625  [ 4544/ 6400]\n",
      "loss: 0.046875  [ 5184/ 6400]\n",
      "loss: 4.828125  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.015625  [   64/ 6400]\n",
      "loss: 26.546875  [  704/ 6400]\n",
      "loss: 8.296875  [ 1344/ 6400]\n",
      "loss: 0.031250  [ 1984/ 6400]\n",
      "loss: 15.031250  [ 2624/ 6400]\n",
      "loss: 0.015625  [ 3264/ 6400]\n",
      "loss: 1.593750  [ 3904/ 6400]\n",
      "loss: 13.343750  [ 4544/ 6400]\n",
      "loss: 4.015625  [ 5184/ 6400]\n",
      "loss: 0.000000  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 10.593750  [   64/ 6400]\n",
      "loss: 0.046875  [  704/ 6400]\n",
      "loss: 23.781250  [ 1344/ 6400]\n",
      "loss: 22.687500  [ 1984/ 6400]\n",
      "loss: 24.828125  [ 2624/ 6400]\n",
      "loss: 8.296875  [ 3264/ 6400]\n",
      "loss: 1.890625  [ 3904/ 6400]\n",
      "loss: 11.062500  [ 4544/ 6400]\n",
      "loss: 4.546875  [ 5184/ 6400]\n",
      "loss: 11.484375  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 16.031250  [   64/ 6400]\n",
      "loss: 23.281250  [  704/ 6400]\n",
      "loss: 26.343750  [ 1344/ 6400]\n",
      "loss: 9.046875  [ 1984/ 6400]\n",
      "loss: 0.031250  [ 2624/ 6400]\n",
      "loss: 2.656250  [ 3264/ 6400]\n",
      "loss: 36.015625  [ 3904/ 6400]\n",
      "loss: 29.656250  [ 4544/ 6400]\n",
      "loss: 0.000000  [ 5184/ 6400]\n",
      "loss: 102.906250  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.093750  [   64/ 6400]\n",
      "loss: 3.546875  [  704/ 6400]\n",
      "loss: 16.734375  [ 1344/ 6400]\n",
      "loss: 80.656250  [ 1984/ 6400]\n",
      "loss: 100.609375  [ 2624/ 6400]\n",
      "loss: 13.187500  [ 3264/ 6400]\n",
      "loss: 0.015625  [ 3904/ 6400]\n",
      "loss: 15.296875  [ 4544/ 6400]\n",
      "loss: 252.046875  [ 5184/ 6400]\n",
      "loss: 10.718750  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 254.296875  [   64/ 6400]\n",
      "loss: 13.546875  [  704/ 6400]\n",
      "loss: 1.234375  [ 1344/ 6400]\n",
      "loss: 18.078125  [ 1984/ 6400]\n",
      "loss: 0.015625  [ 2624/ 6400]\n",
      "loss: 2.671875  [ 3264/ 6400]\n",
      "loss: 49.937500  [ 3904/ 6400]\n",
      "loss: 75.109375  [ 4544/ 6400]\n",
      "loss: 0.031250  [ 5184/ 6400]\n",
      "loss: 61.953125  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 6.265625  [   64/ 6400]\n",
      "loss: 5.640625  [  704/ 6400]\n",
      "loss: 2.640625  [ 1344/ 6400]\n",
      "loss: 19.656250  [ 1984/ 6400]\n",
      "loss: 52.078125  [ 2624/ 6400]\n",
      "loss: 24.281250  [ 3264/ 6400]\n",
      "loss: 20.531250  [ 3904/ 6400]\n",
      "loss: 2.640625  [ 4544/ 6400]\n",
      "loss: 14.156250  [ 5184/ 6400]\n",
      "loss: 144.875000  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 26.328125  [   64/ 6400]\n",
      "loss: 123.781250  [  704/ 6400]\n",
      "loss: 0.046875  [ 1344/ 6400]\n",
      "loss: 16.000000  [ 1984/ 6400]\n",
      "loss: 1.921875  [ 2624/ 6400]\n",
      "loss: 34.687500  [ 3264/ 6400]\n",
      "loss: 102.531250  [ 3904/ 6400]\n",
      "loss: 5.015625  [ 4544/ 6400]\n",
      "loss: 4.562500  [ 5184/ 6400]\n",
      "loss: 6.937500  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.015625  [   64/ 6400]\n",
      "loss: 42.109375  [  704/ 6400]\n",
      "loss: 43.031250  [ 1344/ 6400]\n",
      "loss: 0.062500  [ 1984/ 6400]\n",
      "loss: 0.062500  [ 2624/ 6400]\n",
      "loss: 5.671875  [ 3264/ 6400]\n",
      "loss: 14.468750  [ 3904/ 6400]\n",
      "loss: 0.046875  [ 4544/ 6400]\n",
      "loss: 31.078125  [ 5184/ 6400]\n",
      "loss: 24.781250  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b9019",
   "metadata": {},
   "source": [
    "# Evaluation of the model / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dfe68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
