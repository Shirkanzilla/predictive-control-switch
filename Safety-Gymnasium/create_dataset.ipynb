{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fdaa2e2",
   "metadata": {},
   "source": [
    "# Methods for loading a trained agent provided by Markel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448bd6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from gymnasium.spaces import Box\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from omnisafe.common import Normalizer\n",
    "from omnisafe.envs.wrapper import ActionRepeat, ActionScale, ObsNormalize, TimeLimit\n",
    "from omnisafe.models.actor_critic.constraint_actor_q_critic import ConstraintActorQCritic\n",
    "from omnisafe.utils.config import Config\n",
    "from omnisafe.envs.core import CMDP, make\n",
    "from omnisafe.algorithms.model_based.base.ensemble import EnsembleDynamicsModel\n",
    "from omnisafe.models.actor import ActorBuilder\n",
    "from typing import Dict, Tuple, Any\n",
    "\n",
    "\n",
    "def _load_model_and_env(\n",
    "    save_dir: str,\n",
    "    model_name: str,\n",
    "    cfgs: Config,\n",
    "    env_kwargs: Dict[str, Any],\n",
    ") -> None:\n",
    "    \"\"\"Load the model from the save directory.\n",
    "\n",
    "    Args:\n",
    "        save_dir (str): Directory where the model is saved.\n",
    "        model_name (str): Name of the model.\n",
    "        env_kwargs (dict[str, Any]): Keyword arguments for the environment.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the model is not found.\n",
    "    \"\"\"\n",
    "    # load the saved model\n",
    "    model_path = os.path.join(save_dir, 'torch_save', model_name)\n",
    "    try:\n",
    "        model_params = torch.load(model_path)\n",
    "    except FileNotFoundError as error:\n",
    "        raise FileNotFoundError('The model is not found in the save directory.') from error\n",
    "\n",
    "    # load the environment\n",
    "    env = make(**env_kwargs)\n",
    "\n",
    "    observation_space = env.observation_space\n",
    "    action_space = env.action_space\n",
    "    if 'Saute' in cfgs['algo'] or 'Simmer' in cfgs['algo']:\n",
    "        safety_budget = (\n",
    "            cfgs.algo_cfgs.safety_budget\n",
    "            * (1 - cfgs.algo_cfgs.saute_gamma**cfgs.algo_cfgs.max_ep_len)\n",
    "            / (1 - cfgs.algo_cfgs.saute_gamma)\n",
    "            / cfgs.algo_cfgs.max_ep_len\n",
    "            * torch.ones(1)\n",
    "        )\n",
    "    assert isinstance(observation_space, Box), 'The observation space must be Box.'\n",
    "    assert isinstance(action_space, Box), 'The action space must be Box.'\n",
    "\n",
    "    if cfgs['algo_cfgs']['obs_normalize']:\n",
    "        obs_normalizer = Normalizer(shape=observation_space.shape, clip=5)\n",
    "        obs_normalizer.load_state_dict(model_params['obs_normalizer'])\n",
    "        env = ObsNormalize(env, device=torch.device('cpu'), norm=obs_normalizer)\n",
    "    if env.need_time_limit_wrapper:\n",
    "        env = TimeLimit(env, device=torch.device('cpu'), time_limit=1000)\n",
    "    env = ActionScale(env, device=torch.device('cpu'), low=-1.0, high=1.0)\n",
    "\n",
    "    if hasattr(cfgs['algo_cfgs'], 'action_repeat'):\n",
    "        env = ActionRepeat(\n",
    "            env,\n",
    "            device=torch.device('cpu'),\n",
    "            times=cfgs['algo_cfgs']['action_repeat'],\n",
    "        )\n",
    "    if hasattr(cfgs, 'algo') and cfgs['algo'] in [\n",
    "        'LOOP',\n",
    "        'SafeLOOP',\n",
    "        'PETS',\n",
    "        'CAPPETS',\n",
    "        'RCEPETS',\n",
    "        'CCEPETS',\n",
    "    ]:\n",
    "        dynamics_state_space = (\n",
    "            env.coordinate_observation_space\n",
    "            if env.coordinate_observation_space is not None\n",
    "            else env.observation_space\n",
    "        )\n",
    "        assert env.action_space is not None and isinstance(\n",
    "            env.action_space.shape,\n",
    "            tuple,\n",
    "        )\n",
    "        if isinstance(env.action_space, Box):\n",
    "            action_space = env.action_space\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        if cfgs['algo'] in ['LOOP', 'SafeLOOP']:\n",
    "            actor_critic = ConstraintActorQCritic(\n",
    "                obs_space=dynamics_state_space,\n",
    "                act_space=action_space,\n",
    "                model_cfgs=cfgs.model_cfgs,\n",
    "                epochs=1,\n",
    "            )\n",
    "        if actor_critic is not None:\n",
    "            actor_critic.load_state_dict(model_params['actor_critic'])\n",
    "            actor_critic.to('cpu')\n",
    "        dynamics = EnsembleDynamicsModel(\n",
    "            model_cfgs=cfgs.dynamics_cfgs,\n",
    "            device=torch.device('cpu'),\n",
    "            state_shape=dynamics_state_space.shape,\n",
    "            action_shape=action_space.shape,\n",
    "            actor_critic=actor_critic,\n",
    "            rew_func=None,\n",
    "            cost_func=env.get_cost_from_obs_tensor,\n",
    "            terminal_func=None,\n",
    "        )\n",
    "        dynamics.ensemble_model.load_state_dict(model_params['dynamics'])\n",
    "        dynamics.ensemble_model.to('cpu')\n",
    "        if cfgs['algo'] in ['CCEPETS', 'RCEPETS', 'SafeLOOP']:\n",
    "            algo_to_planner = {\n",
    "                'CCEPETS': (\n",
    "                    'CCEPlanner',\n",
    "                    {'cost_limit': cfgs['algo_cfgs']['cost_limit']},\n",
    "                ),\n",
    "                'RCEPETS': (\n",
    "                    'RCEPlanner',\n",
    "                    {'cost_limit': cfgs['algo_cfgs']['cost_limit']},\n",
    "                ),\n",
    "                'SafeLOOP': (\n",
    "                    'SafeARCPlanner',\n",
    "                    {\n",
    "                        'cost_limit': cfgs['algo_cfgs']['cost_limit'],\n",
    "                        'actor_critic': actor_critic,\n",
    "                    },\n",
    "                ),\n",
    "            }\n",
    "        elif cfgs['algo'] in ['PETS', 'LOOP']:\n",
    "            algo_to_planner = {\n",
    "                'PETS': ('CEMPlanner', {}),\n",
    "                'LOOP': ('ARCPlanner', {'actor_critic': actor_critic}),\n",
    "            }\n",
    "        elif cfgs['algo'] in ['CAPPETS']:\n",
    "            lagrange: torch.nn.Parameter = torch.nn.Parameter(\n",
    "                model_params['lagrangian_multiplier'].to('cpu'),\n",
    "                requires_grad=False,\n",
    "            )\n",
    "            algo_to_planner = {\n",
    "                'CAPPETS': (\n",
    "                    'CAPPlanner',\n",
    "                    {\n",
    "                        'cost_limit': cfgs['lagrange_cfgs']['cost_limit'],\n",
    "                        'lagrange': lagrange,\n",
    "                    },\n",
    "                ),\n",
    "            }\n",
    "        planner_name = algo_to_planner[cfgs['algo']][0]\n",
    "        planner_special_cfgs = algo_to_planner[cfgs['algo']][1]\n",
    "        planner_cls = globals()[f'{planner_name}']\n",
    "        planner = planner_cls(\n",
    "            dynamics=dynamics,\n",
    "            planner_cfgs=cfgs.planner_cfgs,\n",
    "            gamma=float(cfgs.algo_cfgs.gamma),\n",
    "            cost_gamma=float(cfgs.algo_cfgs.cost_gamma),\n",
    "            dynamics_state_shape=dynamics_state_space.shape,\n",
    "            action_shape=action_space.shape,\n",
    "            action_max=1.0,\n",
    "            action_min=-1.0,\n",
    "            device='cpu',\n",
    "            **planner_special_cfgs,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        if 'Saute' in cfgs['algo'] or 'Simmer' in cfgs['algo']:\n",
    "            observation_space = Box(\n",
    "                low=np.hstack((observation_space.low, -np.inf)),\n",
    "                high=np.hstack((observation_space.high, np.inf)),\n",
    "                shape=(observation_space.shape[0] + 1,),\n",
    "            )\n",
    "        actor_type = cfgs['model_cfgs']['actor_type']\n",
    "        pi_cfg = cfgs['model_cfgs']['actor']\n",
    "        weight_initialization_mode = cfgs['model_cfgs']['weight_initialization_mode']\n",
    "        actor_builder = ActorBuilder(\n",
    "            obs_space=observation_space,\n",
    "            act_space=action_space,\n",
    "            hidden_sizes=pi_cfg['hidden_sizes'],\n",
    "            activation=pi_cfg['activation'],\n",
    "            weight_initialization_mode=weight_initialization_mode,\n",
    "        )\n",
    "        actor = actor_builder.build_actor(actor_type)\n",
    "        actor.load_state_dict(model_params['pi'])\n",
    "\n",
    "    return env, actor\n",
    "\n",
    "\n",
    "def _load_cfgs(save_dir):\n",
    "    cfg_path = os.path.join(save_dir, 'config.json')\n",
    "    try:\n",
    "        with open(cfg_path, encoding='utf-8') as file:\n",
    "            kwargs = json.load(file)\n",
    "    except FileNotFoundError as error:\n",
    "        raise FileNotFoundError(\n",
    "            f'The config file is not found in the save directory{save_dir}.',\n",
    "        ) from error\n",
    "    return Config.dict2config(kwargs)\n",
    "\n",
    "\n",
    "# LOG_DIR should contain two things:\n",
    "# 1. config.json\n",
    "# 2. torch_save/{model_name}\n",
    "#\n",
    "# model_name usually looks like 'epoch-500.pt'\n",
    "def load_guide(save_dir, model_name) -> Tuple[CMDP, ConstraintActorQCritic]:\n",
    "    cfgs = _load_cfgs(save_dir)\n",
    "\n",
    "    env_kwargs = {\n",
    "        'env_id': cfgs['env_id'],\n",
    "        'num_envs': 1,\n",
    "    }\n",
    "\n",
    "    env, actor = _load_model_and_env(save_dir, model_name, cfgs, env_kwargs)\n",
    "    return env, actor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171f0d8",
   "metadata": {},
   "source": [
    "# Generating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6ac7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omnisafe.models.actor import GaussianLearningActor\n",
    "import safety_gymnasium\n",
    "import torch\n",
    "\n",
    "env = safety_gymnasium.make('SafetyPointGoal1-v0', max_episode_steps=1000)\n",
    "\n",
    "def create_random_agent(env, hidden_layers=[255,255,255,255], activation='relu', weight_initialization_mode='orthogonal'):\n",
    "    obs_space = env.observation_space\n",
    "    act_space = env.action_space\n",
    "    return GaussianLearningActor(obs_space, act_space, hidden_layers, activation=activation, weight_initialization_mode=weight_initialization_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75645ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(Dict('accelerometer': Box(-inf, inf, (3,), float64), 'velocimeter': Box(-inf, inf, (3,), float64), 'gyro': Box(-inf, inf, (3,), float64), 'magnetometer': Box(-inf, inf, (3,), float64), 'goal_lidar': Box(0.0, 1.0, (16,), float64), 'hazards_lidar': Box(0.0, 1.0, (16,), float64), 'vases_lidar': Box(0.0, 1.0, (16,), float64)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.obs_space_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece55959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-1.0, 1.0, (2,), float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c33b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def run_trajectory(env, agent, safe_agent, min_rand_steps=100, max_rand_steps=400, cost_window=200, deterministic=True):\n",
    "    observation, info = env.reset()\n",
    "    episode_over = False\n",
    "    is_sampling = False\n",
    "    sampled_cost = 0\n",
    "    sampling_step = 0\n",
    "    agent_instance_for_pos = env.unwrapped.__getattribute__(\"task\").agent\n",
    "    data = []\n",
    "    labels = []\n",
    "    # get a random number for the amount of steps the random agent should take before a sample is created\n",
    "    num_steps = np.random.randint(min_rand_steps, max_rand_steps)\n",
    "    # gather data\n",
    "    for i in range(num_steps):\n",
    "        # Discard trajectory if the agent moves out of the checkered 7x7 space, coordinates were tested manually\n",
    "        if abs(agent_instance_for_pos.pos[0]) >= 3.5 or abs(agent_instance_for_pos.pos[1]) >= 3.5: \n",
    "            break\n",
    "        obs_tensor = torch.from_numpy(observation).float()\n",
    "        action = agent.predict(obs_tensor, deterministic=deterministic).detach().numpy()\n",
    "        if i == num_steps - 1:\n",
    "            data.append(np.append(observation, action)) \n",
    "        observation, reward, cost, terminated, truncated, info = env.step(action)\n",
    "        episode_over = terminated or truncated\n",
    "        if episode_over:\n",
    "            break\n",
    "    if not episode_over:\n",
    "        # sample with the pre trained agent\n",
    "        for i in range(cost_window):\n",
    "            obs_tensor = torch.from_numpy(observation).float()\n",
    "            action = safe_agent.predict(obs_tensor, deterministic=deterministic).detach().numpy()\n",
    "            observation, reward, cost, terminated, truncated, info = env.step(action)\n",
    "            episode_over = terminated or truncated\n",
    "            sampled_cost += cost\n",
    "            sampling_step += 1\n",
    "            if episode_over or i == cost_window - 1:\n",
    "                labels.append(sampled_cost)\n",
    "                break\n",
    "    if len(labels) == 0:\n",
    "        # If episode ended before sampling could happen, return an empty data and labels array\n",
    "        # More of a safety measure, probably obsolete\n",
    "        data = []\n",
    "    if len(data) == 0:\n",
    "        labels = []\n",
    "    env.close()\n",
    "    # assertion to make sure every data point has a label\n",
    "    assert len(data) == len(labels)\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9818047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_968/1383116929.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_params = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# load my saved trained agent\n",
    "safe_agent = load_guide(\"../runs/PPOLag-{SafetyPointGoal1-v0}/seed-000-2025-05-13-17-51-08\", \"epoch-50.pt\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8497760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = run_trajectory(env, create_random_agent(env), safe_agent)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1fffc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f6b1075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 62)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca182c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "844dddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_dataset(env, safe_agent, amount=1000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for _ in tqdm(range(amount), desc=\"Generating data points\", unit=\" sample \"):\n",
    "        data_i = []\n",
    "        while len(data_i) == 0: # Ensure that a sample is generated\n",
    "            data_i, labels_i = run_trajectory(env, create_random_agent(env), safe_agent)\n",
    "        data.append(data_i)\n",
    "        labels.append(labels_i)\n",
    "    return np.concatenate(data, axis=0)[:amount], np.concatenate(labels, axis=0)[:amount]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa23b9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data points: 100%|██████████| 100000/100000 [34:24:11<00:00,  1.24s/ sample ]  \n"
     ]
    }
   ],
   "source": [
    "data, labels = generate_dataset(env, safe_agent, amount=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e063f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.769528  , 11.532802  ,  9.81      , ...,  0.        ,\n",
       "        -1.25018418,  0.04445577],\n",
       "       [-1.78246786, -1.58724729,  9.81      , ...,  0.        ,\n",
       "        -0.14957084,  1.56127739],\n",
       "       [ 2.15435992,  1.39720127,  9.81      , ...,  0.        ,\n",
       "         1.01796758,  1.85080564],\n",
       "       ...,\n",
       "       [-1.83884534,  3.34935218,  9.81      , ...,  0.        ,\n",
       "        -0.72516757,  0.78899771],\n",
       "       [-1.92601718, -1.2521395 ,  9.81      , ...,  0.        ,\n",
       "        -1.02038395,  1.09551978],\n",
       "       [ 2.16149193, -1.39934431,  9.81      , ...,  0.        ,\n",
       "         0.90575391, -1.78019655]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42dcdd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 62)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a61ad28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ..., 46.,  0., 16.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7962301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455af4aa",
   "metadata": {},
   "source": [
    "# Preprocessing the dataset for better NN performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "17f4ca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/user/bachelor/RL/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy in /home/user/bachelor/RL/lib/python3.8/site-packages (1.10.1)\n",
      "Requirement already satisfied: pandas in /home/user/bachelor/RL/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/bachelor/RL/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/user/bachelor/RL/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/user/bachelor/RL/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn scipy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06585e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_column_names = ['accelerometer0', 'accelerometer1', 'accelerometer2', 'velocimeter0', 'velocimeter1', 'velocimeter2', 'gyro0', 'gyro1', 'gyro2', 'magnetometer0', 'magnetometer1', 'magnetometer2']\n",
    "for key in ['goal_lidar', 'hazards_lidar', 'vases_lidar']:\n",
    "    for i in range(16):\n",
    "        obs_column_names.append(key+str(i))\n",
    "obs_column_names.append(\"action0\")\n",
    "obs_column_names.append(\"action1\")\n",
    "len(obs_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1fcfd790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "      <th>exp_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.769528</td>\n",
       "      <td>11.532802</td>\n",
       "      <td>9.81</td>\n",
       "      <td>-1.098218</td>\n",
       "      <td>0.577155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.499018</td>\n",
       "      <td>-0.470912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.250184</td>\n",
       "      <td>0.044456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.782468</td>\n",
       "      <td>-1.587247</td>\n",
       "      <td>9.81</td>\n",
       "      <td>-0.483206</td>\n",
       "      <td>0.823411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3.031644</td>\n",
       "      <td>-0.458862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587877</td>\n",
       "      <td>0.128005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149571</td>\n",
       "      <td>1.561277</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.154360</td>\n",
       "      <td>1.397201</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.470486</td>\n",
       "      <td>-0.724769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2.972175</td>\n",
       "      <td>-0.166978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.729051</td>\n",
       "      <td>0.532690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.017968</td>\n",
       "      <td>1.850806</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.243852</td>\n",
       "      <td>-1.231428</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0.424247</td>\n",
       "      <td>0.638764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.975484</td>\n",
       "      <td>0.480087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637103</td>\n",
       "      <td>0.014392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086816</td>\n",
       "      <td>-1.768033</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.146395</td>\n",
       "      <td>-11.298087</td>\n",
       "      <td>9.81</td>\n",
       "      <td>1.424790</td>\n",
       "      <td>-0.295172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.274193</td>\n",
       "      <td>-0.203405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619345</td>\n",
       "      <td>0.140426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer0  accelerometer1  accelerometer2  velocimeter0  velocimeter1  \\\n",
       "0       -0.769528       11.532802            9.81     -1.098218      0.577155   \n",
       "1       -1.782468       -1.587247            9.81     -0.483206      0.823411   \n",
       "2        2.154360        1.397201            9.81      0.470486     -0.724769   \n",
       "3        2.243852       -1.231428            9.81      0.424247      0.638764   \n",
       "4        0.146395      -11.298087            9.81      1.424790     -0.295172   \n",
       "\n",
       "   velocimeter2  gyro0  gyro1     gyro2  magnetometer0  ...  vases_lidar9  \\\n",
       "0           0.0    0.0   -0.0  0.499018      -0.470912  ...      0.000000   \n",
       "1           0.0    0.0   -0.0  3.031644      -0.458862  ...      0.587877   \n",
       "2           0.0    0.0   -0.0  2.972175      -0.166978  ...      0.729051   \n",
       "3           0.0    0.0    0.0 -2.975484       0.480087  ...      0.637103   \n",
       "4           0.0    0.0    0.0 -0.274193      -0.203405  ...      0.000000   \n",
       "\n",
       "   vases_lidar10  vases_lidar11  vases_lidar12  vases_lidar13  vases_lidar14  \\\n",
       "0       0.000000            0.0            0.0            0.0            0.0   \n",
       "1       0.128005            0.0            0.0            0.0            0.0   \n",
       "2       0.532690            0.0            0.0            0.0            0.0   \n",
       "3       0.014392            0.0            0.0            0.0            0.0   \n",
       "4       0.000000            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   vases_lidar15   action0   action1  exp_cost  \n",
       "0            0.0 -1.250184  0.044456       0.0  \n",
       "1            0.0 -0.149571  1.561277       0.0  \n",
       "2            0.0  1.017968  1.850806       0.0  \n",
       "3            0.0  0.086816 -1.768033       0.0  \n",
       "4            0.0  0.619345  0.140426       0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=data, columns=obs_column_names)\n",
    "df['exp_cost'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "569467b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the create dataset in a pickle file\n",
    "df.to_pickle(\"SafetyPointGoal1Dataset0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b30392b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "      <th>exp_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069010</td>\n",
       "      <td>-0.001533</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.023808</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.053256</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>9.916320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.926543</td>\n",
       "      <td>6.733668</td>\n",
       "      <td>1.500540e-15</td>\n",
       "      <td>0.718428</td>\n",
       "      <td>0.577444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374169</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152026</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>0.151848</td>\n",
       "      <td>0.151066</td>\n",
       "      <td>0.150142</td>\n",
       "      <td>0.151592</td>\n",
       "      <td>0.153017</td>\n",
       "      <td>1.072705</td>\n",
       "      <td>1.115400</td>\n",
       "      <td>19.740233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.452849</td>\n",
       "      <td>-19.989003</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>-1.499778</td>\n",
       "      <td>-1.081251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.038259</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.609840</td>\n",
       "      <td>-4.453977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.879547</td>\n",
       "      <td>-1.475206</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>-0.453180</td>\n",
       "      <td>-0.639035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.815359</td>\n",
       "      <td>-0.351950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.686058</td>\n",
       "      <td>-0.902644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.023382</td>\n",
       "      <td>-0.015324</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.020276</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.059706</td>\n",
       "      <td>1.469249</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.504858</td>\n",
       "      <td>0.639037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.808083</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680545</td>\n",
       "      <td>0.902431</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.351211</td>\n",
       "      <td>19.983345</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>1.499773</td>\n",
       "      <td>1.053874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.039440</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933722</td>\n",
       "      <td>0.933531</td>\n",
       "      <td>0.933638</td>\n",
       "      <td>0.933393</td>\n",
       "      <td>0.932465</td>\n",
       "      <td>0.922693</td>\n",
       "      <td>0.917074</td>\n",
       "      <td>7.266669</td>\n",
       "      <td>4.720612</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accelerometer0  accelerometer1  accelerometer2   velocimeter0  \\\n",
       "count   100000.000000   100000.000000    1.000000e+05  100000.000000   \n",
       "mean         0.069010       -0.001533    9.810000e+00       0.023808   \n",
       "std          1.926543        6.733668    1.500540e-15       0.718428   \n",
       "min         -5.452849      -19.989003    9.810000e+00      -1.499778   \n",
       "25%         -1.879547       -1.475206    9.810000e+00      -0.453180   \n",
       "50%          0.023382       -0.015324    9.810000e+00       0.020276   \n",
       "75%          2.059706        1.469249    9.810000e+00       0.504858   \n",
       "max          5.351211       19.983345    9.810000e+00       1.499773   \n",
       "\n",
       "        velocimeter1  velocimeter2     gyro0     gyro1          gyro2  \\\n",
       "count  100000.000000      100000.0  100000.0  100000.0  100000.000000   \n",
       "mean        0.001872           0.0       0.0       0.0       0.006035   \n",
       "std         0.577444           0.0       0.0       0.0       2.374169   \n",
       "min        -1.081251           0.0       0.0       0.0      -3.038259   \n",
       "25%        -0.639035           0.0       0.0       0.0      -2.815359   \n",
       "50%         0.002603           0.0       0.0       0.0       0.020454   \n",
       "75%         0.639037           0.0       0.0       0.0       2.808083   \n",
       "max         1.053874           0.0       0.0       0.0       3.039440   \n",
       "\n",
       "       magnetometer0  ...   vases_lidar9  vases_lidar10  vases_lidar11  \\\n",
       "count  100000.000000  ...  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.000537  ...       0.053299       0.053256       0.053404   \n",
       "std         0.352747  ...       0.152026       0.151757       0.151848   \n",
       "min        -0.500000  ...       0.000000       0.000000       0.000000   \n",
       "25%        -0.351950  ...       0.000000       0.000000       0.000000   \n",
       "50%        -0.001902  ...       0.000000       0.000000       0.000000   \n",
       "75%         0.352273  ...       0.000000       0.000000       0.000000   \n",
       "max         0.500000  ...       0.933722       0.933531       0.933638   \n",
       "\n",
       "       vases_lidar12  vases_lidar13  vases_lidar14  vases_lidar15  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.053087       0.052577       0.053171       0.053593   \n",
       "std         0.151066       0.150142       0.151592       0.153017   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         0.933393       0.932465       0.922693       0.917074   \n",
       "\n",
       "             action0        action1       exp_cost  \n",
       "count  100000.000000  100000.000000  100000.000000  \n",
       "mean        0.000356       0.003248       9.916320  \n",
       "std         1.072705       1.115400      19.740233  \n",
       "min        -5.609840      -4.453977       0.000000  \n",
       "25%        -0.686058      -0.902644       0.000000  \n",
       "50%         0.006072       0.003101       0.000000  \n",
       "75%         0.680545       0.902431      15.000000  \n",
       "max         7.266669       4.720612     200.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d695970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset into data and label again\n",
    "X = df.drop(columns=[\"exp_cost\"])\n",
    "y = df.exp_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "784054d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar8</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.227414</td>\n",
       "      <td>0.313197</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.462505</td>\n",
       "      <td>0.557831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.694919</td>\n",
       "      <td>0.939323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052244</td>\n",
       "      <td>0.625564</td>\n",
       "      <td>0.579633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299955</td>\n",
       "      <td>0.566695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188080</td>\n",
       "      <td>0.899850</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.544380</td>\n",
       "      <td>0.692104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712890</td>\n",
       "      <td>0.331304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611867</td>\n",
       "      <td>0.182172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674924</td>\n",
       "      <td>0.477102</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.665557</td>\n",
       "      <td>0.537963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969010</td>\n",
       "      <td>0.496035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.805797</td>\n",
       "      <td>0.594796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.675388</td>\n",
       "      <td>0.386923</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.648260</td>\n",
       "      <td>0.513752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812540</td>\n",
       "      <td>0.923378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492159</td>\n",
       "      <td>0.341937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.647776</td>\n",
       "      <td>0.497385</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>0.597936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.950792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636366</td>\n",
       "      <td>0.374744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer0  accelerometer1  accelerometer2  velocimeter0  velocimeter1  \\\n",
       "0        0.227414        0.313197            1.00      0.462505      0.557831   \n",
       "1        0.188080        0.899850            1.00      0.544380      0.692104   \n",
       "2        0.674924        0.477102            0.50      0.665557      0.537963   \n",
       "3        0.675388        0.386923            1.00      0.648260      0.513752   \n",
       "4        0.647776        0.497385            0.25      0.722633      0.597936   \n",
       "\n",
       "   velocimeter2  gyro0  gyro1     gyro2  magnetometer0  ...  vases_lidar8  \\\n",
       "0           0.0    0.0    0.0  0.694919       0.939323  ...           0.0   \n",
       "1           0.0    0.0    0.0  0.712890       0.331304  ...           0.0   \n",
       "2           0.0    0.0    0.0  0.969010       0.496035  ...           0.0   \n",
       "3           0.0    0.0    0.0  0.812540       0.923378  ...           0.0   \n",
       "4           0.0    0.0    0.0  0.016810       0.950792  ...           0.0   \n",
       "\n",
       "   vases_lidar9  vases_lidar10  vases_lidar11  vases_lidar12  vases_lidar13  \\\n",
       "0           0.0            0.0       0.052244       0.625564       0.579633   \n",
       "1           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "2           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "3           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "4           0.0            0.0       0.000000       0.000000       0.000000   \n",
       "\n",
       "   vases_lidar14  vases_lidar15   action0   action1  \n",
       "0            0.0            0.0  0.299955  0.566695  \n",
       "1            0.0            0.0  0.611867  0.182172  \n",
       "2            0.0            0.0  0.805797  0.594796  \n",
       "3            0.0            0.0  0.492159  0.341937  \n",
       "4            0.0            0.0  0.636366  0.374744  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler((0,1))\n",
    "scaled = scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled, columns=obs_column_names)\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "def8a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into train, test and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a3b709da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 62)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c6022018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 62)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "833deaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 62)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5f1131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert dataset into a TensorDataset\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train.values.astype(np.float32)), torch.from_numpy(y_train.values.astype(np.float32)))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(X_validate.values.astype(np.float32)), torch.from_numpy(y_validate.values.astype(np.float32)))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test.values.astype(np.float32)), torch.from_numpy(y_test.values.astype(np.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6fa2a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Putting data into dataloaders for PyTorch\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6380a50",
   "metadata": {},
   "source": [
    "# Building a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "359125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExpectedCostNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpectedCostNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(62, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6f2c7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "44c476ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpectedCostNN(\n",
      "  (fc1): Linear(in_features=62, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ExpectedCostNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e230bc6",
   "metadata": {},
   "source": [
    "# Training a neural network on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f536ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze()\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02b46771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted to regression problem from original code https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze()\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7c9b6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.031250  [   64/ 6400]\n",
      "loss: 151.093750  [  704/ 6400]\n",
      "loss: 1.593750  [ 1344/ 6400]\n",
      "loss: 45.562500  [ 1984/ 6400]\n",
      "loss: 0.062500  [ 2624/ 6400]\n",
      "loss: 1.296875  [ 3264/ 6400]\n",
      "loss: 30.078125  [ 3904/ 6400]\n",
      "loss: 25.765625  [ 4544/ 6400]\n",
      "loss: 16.000000  [ 5184/ 6400]\n",
      "loss: 48.421875  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.500000  [   64/ 6400]\n",
      "loss: 1.468750  [  704/ 6400]\n",
      "loss: 22.390625  [ 1344/ 6400]\n",
      "loss: 29.328125  [ 1984/ 6400]\n",
      "loss: 8.984375  [ 2624/ 6400]\n",
      "loss: 18.656250  [ 3264/ 6400]\n",
      "loss: 111.781250  [ 3904/ 6400]\n",
      "loss: 0.015625  [ 4544/ 6400]\n",
      "loss: 0.046875  [ 5184/ 6400]\n",
      "loss: 4.828125  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.015625  [   64/ 6400]\n",
      "loss: 26.546875  [  704/ 6400]\n",
      "loss: 8.296875  [ 1344/ 6400]\n",
      "loss: 0.031250  [ 1984/ 6400]\n",
      "loss: 15.031250  [ 2624/ 6400]\n",
      "loss: 0.015625  [ 3264/ 6400]\n",
      "loss: 1.593750  [ 3904/ 6400]\n",
      "loss: 13.343750  [ 4544/ 6400]\n",
      "loss: 4.015625  [ 5184/ 6400]\n",
      "loss: 0.000000  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 10.593750  [   64/ 6400]\n",
      "loss: 0.046875  [  704/ 6400]\n",
      "loss: 23.781250  [ 1344/ 6400]\n",
      "loss: 22.687500  [ 1984/ 6400]\n",
      "loss: 24.828125  [ 2624/ 6400]\n",
      "loss: 8.296875  [ 3264/ 6400]\n",
      "loss: 1.890625  [ 3904/ 6400]\n",
      "loss: 11.062500  [ 4544/ 6400]\n",
      "loss: 4.546875  [ 5184/ 6400]\n",
      "loss: 11.484375  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 16.031250  [   64/ 6400]\n",
      "loss: 23.281250  [  704/ 6400]\n",
      "loss: 26.343750  [ 1344/ 6400]\n",
      "loss: 9.046875  [ 1984/ 6400]\n",
      "loss: 0.031250  [ 2624/ 6400]\n",
      "loss: 2.656250  [ 3264/ 6400]\n",
      "loss: 36.015625  [ 3904/ 6400]\n",
      "loss: 29.656250  [ 4544/ 6400]\n",
      "loss: 0.000000  [ 5184/ 6400]\n",
      "loss: 102.906250  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 3.093750  [   64/ 6400]\n",
      "loss: 3.546875  [  704/ 6400]\n",
      "loss: 16.734375  [ 1344/ 6400]\n",
      "loss: 80.656250  [ 1984/ 6400]\n",
      "loss: 100.609375  [ 2624/ 6400]\n",
      "loss: 13.187500  [ 3264/ 6400]\n",
      "loss: 0.015625  [ 3904/ 6400]\n",
      "loss: 15.296875  [ 4544/ 6400]\n",
      "loss: 252.046875  [ 5184/ 6400]\n",
      "loss: 10.718750  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 254.296875  [   64/ 6400]\n",
      "loss: 13.546875  [  704/ 6400]\n",
      "loss: 1.234375  [ 1344/ 6400]\n",
      "loss: 18.078125  [ 1984/ 6400]\n",
      "loss: 0.015625  [ 2624/ 6400]\n",
      "loss: 2.671875  [ 3264/ 6400]\n",
      "loss: 49.937500  [ 3904/ 6400]\n",
      "loss: 75.109375  [ 4544/ 6400]\n",
      "loss: 0.031250  [ 5184/ 6400]\n",
      "loss: 61.953125  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 6.265625  [   64/ 6400]\n",
      "loss: 5.640625  [  704/ 6400]\n",
      "loss: 2.640625  [ 1344/ 6400]\n",
      "loss: 19.656250  [ 1984/ 6400]\n",
      "loss: 52.078125  [ 2624/ 6400]\n",
      "loss: 24.281250  [ 3264/ 6400]\n",
      "loss: 20.531250  [ 3904/ 6400]\n",
      "loss: 2.640625  [ 4544/ 6400]\n",
      "loss: 14.156250  [ 5184/ 6400]\n",
      "loss: 144.875000  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 26.328125  [   64/ 6400]\n",
      "loss: 123.781250  [  704/ 6400]\n",
      "loss: 0.046875  [ 1344/ 6400]\n",
      "loss: 16.000000  [ 1984/ 6400]\n",
      "loss: 1.921875  [ 2624/ 6400]\n",
      "loss: 34.687500  [ 3264/ 6400]\n",
      "loss: 102.531250  [ 3904/ 6400]\n",
      "loss: 5.015625  [ 4544/ 6400]\n",
      "loss: 4.562500  [ 5184/ 6400]\n",
      "loss: 6.937500  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.015625  [   64/ 6400]\n",
      "loss: 42.109375  [  704/ 6400]\n",
      "loss: 43.031250  [ 1344/ 6400]\n",
      "loss: 0.062500  [ 1984/ 6400]\n",
      "loss: 0.062500  [ 2624/ 6400]\n",
      "loss: 5.671875  [ 3264/ 6400]\n",
      "loss: 14.468750  [ 3904/ 6400]\n",
      "loss: 0.046875  [ 4544/ 6400]\n",
      "loss: 31.078125  [ 5184/ 6400]\n",
      "loss: 24.781250  [ 5824/ 6400]\n",
      "Avg loss: 29.622070 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b9019",
   "metadata": {},
   "source": [
    "# Evaluation of the model / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dfe68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
