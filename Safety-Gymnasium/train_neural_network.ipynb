{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a932ccb",
   "metadata": {},
   "source": [
    "# Load the dataset, preprocess it and create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd04ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# set seeds\n",
    "torch.seed = 42\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "667a1b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from pickle file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"SafetyPointGoal1Dataset0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba1a3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>accelerometer2</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>velocimeter2</th>\n",
       "      <th>gyro0</th>\n",
       "      <th>gyro1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "      <th>exp_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069010</td>\n",
       "      <td>-0.001533</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.023808</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053299</td>\n",
       "      <td>0.053256</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>0.053087</td>\n",
       "      <td>0.052577</td>\n",
       "      <td>0.053171</td>\n",
       "      <td>0.053593</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>9.916320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.926543</td>\n",
       "      <td>6.733668</td>\n",
       "      <td>1.500540e-15</td>\n",
       "      <td>0.718428</td>\n",
       "      <td>0.577444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.374169</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152026</td>\n",
       "      <td>0.151757</td>\n",
       "      <td>0.151848</td>\n",
       "      <td>0.151066</td>\n",
       "      <td>0.150142</td>\n",
       "      <td>0.151592</td>\n",
       "      <td>0.153017</td>\n",
       "      <td>1.072705</td>\n",
       "      <td>1.115400</td>\n",
       "      <td>19.740233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.452849</td>\n",
       "      <td>-19.989003</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>-1.499778</td>\n",
       "      <td>-1.081251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.038259</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.609840</td>\n",
       "      <td>-4.453977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.879547</td>\n",
       "      <td>-1.475206</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>-0.453180</td>\n",
       "      <td>-0.639035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.815359</td>\n",
       "      <td>-0.351950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.686058</td>\n",
       "      <td>-0.902644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.023382</td>\n",
       "      <td>-0.015324</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.020276</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.059706</td>\n",
       "      <td>1.469249</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>0.504858</td>\n",
       "      <td>0.639037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.808083</td>\n",
       "      <td>0.352273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680545</td>\n",
       "      <td>0.902431</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.351211</td>\n",
       "      <td>19.983345</td>\n",
       "      <td>9.810000e+00</td>\n",
       "      <td>1.499773</td>\n",
       "      <td>1.053874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.039440</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933722</td>\n",
       "      <td>0.933531</td>\n",
       "      <td>0.933638</td>\n",
       "      <td>0.933393</td>\n",
       "      <td>0.932465</td>\n",
       "      <td>0.922693</td>\n",
       "      <td>0.917074</td>\n",
       "      <td>7.266669</td>\n",
       "      <td>4.720612</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accelerometer0  accelerometer1  accelerometer2   velocimeter0  \\\n",
       "count   100000.000000   100000.000000    1.000000e+05  100000.000000   \n",
       "mean         0.069010       -0.001533    9.810000e+00       0.023808   \n",
       "std          1.926543        6.733668    1.500540e-15       0.718428   \n",
       "min         -5.452849      -19.989003    9.810000e+00      -1.499778   \n",
       "25%         -1.879547       -1.475206    9.810000e+00      -0.453180   \n",
       "50%          0.023382       -0.015324    9.810000e+00       0.020276   \n",
       "75%          2.059706        1.469249    9.810000e+00       0.504858   \n",
       "max          5.351211       19.983345    9.810000e+00       1.499773   \n",
       "\n",
       "        velocimeter1  velocimeter2     gyro0     gyro1          gyro2  \\\n",
       "count  100000.000000      100000.0  100000.0  100000.0  100000.000000   \n",
       "mean        0.001872           0.0       0.0       0.0       0.006035   \n",
       "std         0.577444           0.0       0.0       0.0       2.374169   \n",
       "min        -1.081251           0.0       0.0       0.0      -3.038259   \n",
       "25%        -0.639035           0.0       0.0       0.0      -2.815359   \n",
       "50%         0.002603           0.0       0.0       0.0       0.020454   \n",
       "75%         0.639037           0.0       0.0       0.0       2.808083   \n",
       "max         1.053874           0.0       0.0       0.0       3.039440   \n",
       "\n",
       "       magnetometer0  ...   vases_lidar9  vases_lidar10  vases_lidar11  \\\n",
       "count  100000.000000  ...  100000.000000  100000.000000  100000.000000   \n",
       "mean       -0.000537  ...       0.053299       0.053256       0.053404   \n",
       "std         0.352747  ...       0.152026       0.151757       0.151848   \n",
       "min        -0.500000  ...       0.000000       0.000000       0.000000   \n",
       "25%        -0.351950  ...       0.000000       0.000000       0.000000   \n",
       "50%        -0.001902  ...       0.000000       0.000000       0.000000   \n",
       "75%         0.352273  ...       0.000000       0.000000       0.000000   \n",
       "max         0.500000  ...       0.933722       0.933531       0.933638   \n",
       "\n",
       "       vases_lidar12  vases_lidar13  vases_lidar14  vases_lidar15  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.053087       0.052577       0.053171       0.053593   \n",
       "std         0.151066       0.150142       0.151592       0.153017   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         0.933393       0.932465       0.922693       0.917074   \n",
       "\n",
       "             action0        action1       exp_cost  \n",
       "count  100000.000000  100000.000000  100000.000000  \n",
       "mean        0.000356       0.003248       9.916320  \n",
       "std         1.072705       1.115400      19.740233  \n",
       "min        -5.609840      -4.453977       0.000000  \n",
       "25%        -0.686058      -0.902644       0.000000  \n",
       "50%         0.006072       0.003101       0.000000  \n",
       "75%         0.680545       0.902431      15.000000  \n",
       "max         7.266669       4.720612     200.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd44cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset into data and label again\n",
    "# remove third velocimeter and accelerometer and magnetometer columns as they are for the z-axis and therefore irrelevant\n",
    "# also remove gyro0 and gyro1 as there is no rotation possible on the x and y axis\n",
    "X = df.drop(columns=[\"exp_cost\", \"velocimeter2\", \"accelerometer2\", \"magnetometer2\", \"gyro0\", \"gyro1\"])\n",
    "y = df.exp_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23858d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.8766e+04, 1.3124e+04, 4.7600e+03, 1.8520e+03, 8.0200e+02,\n",
       "        3.7800e+02, 1.8800e+02, 8.2000e+01, 3.6000e+01, 1.2000e+01]),\n",
       " array([  0.,  20.,  40.,  60.,  80., 100., 120., 140., 160., 180., 200.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca57d8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_column_names = ['accelerometer0', 'accelerometer1', 'velocimeter0', 'velocimeter1', 'gyro2', 'magnetometer0', 'magnetometer1']\n",
    "for key in ['goal_lidar', 'hazards_lidar', 'vases_lidar']:\n",
    "    for i in range(16):\n",
    "        obs_column_names.append(key+str(i))\n",
    "obs_column_names.append(\"action0\")\n",
    "obs_column_names.append(\"action1\")\n",
    "len(obs_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4307a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>magnetometer1</th>\n",
       "      <th>goal_lidar0</th>\n",
       "      <th>goal_lidar1</th>\n",
       "      <th>goal_lidar2</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar8</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.433478</td>\n",
       "      <td>0.788590</td>\n",
       "      <td>0.133874</td>\n",
       "      <td>0.776725</td>\n",
       "      <td>0.582009</td>\n",
       "      <td>0.029088</td>\n",
       "      <td>0.668053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338574</td>\n",
       "      <td>0.490314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339722</td>\n",
       "      <td>0.460362</td>\n",
       "      <td>0.338908</td>\n",
       "      <td>0.892061</td>\n",
       "      <td>0.998717</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.698610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492113</td>\n",
       "      <td>0.629606</td>\n",
       "      <td>0.137120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424049</td>\n",
       "      <td>0.655643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.704106</td>\n",
       "      <td>0.535025</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.166961</td>\n",
       "      <td>0.988933</td>\n",
       "      <td>0.333022</td>\n",
       "      <td>0.971294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210128</td>\n",
       "      <td>0.780801</td>\n",
       "      <td>0.570618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514721</td>\n",
       "      <td>0.687201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.712390</td>\n",
       "      <td>0.469264</td>\n",
       "      <td>0.641438</td>\n",
       "      <td>0.805581</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.980087</td>\n",
       "      <td>0.360298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.682326</td>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.442407</td>\n",
       "      <td>0.292759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.518254</td>\n",
       "      <td>0.217423</td>\n",
       "      <td>0.975002</td>\n",
       "      <td>0.368165</td>\n",
       "      <td>0.454788</td>\n",
       "      <td>0.296595</td>\n",
       "      <td>0.043244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483764</td>\n",
       "      <td>0.500775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accelerometer0  accelerometer1  velocimeter0  velocimeter1     gyro2  \\\n",
       "0        0.433478        0.788590      0.133874      0.776725  0.582009   \n",
       "1        0.339722        0.460362      0.338908      0.892061  0.998717   \n",
       "2        0.704106        0.535025      0.656853      0.166961  0.988933   \n",
       "3        0.712390        0.469264      0.641438      0.805581  0.010329   \n",
       "4        0.518254        0.217423      0.975002      0.368165  0.454788   \n",
       "\n",
       "   magnetometer0  magnetometer1  goal_lidar0  goal_lidar1  goal_lidar2  ...  \\\n",
       "0       0.029088       0.668053          0.0          0.0          0.0  ...   \n",
       "1       0.041138       0.698610          0.0          0.0          0.0  ...   \n",
       "2       0.333022       0.971294          0.0          0.0          0.0  ...   \n",
       "3       0.980087       0.360298          0.0          0.0          0.0  ...   \n",
       "4       0.296595       0.043244          0.0          0.0          0.0  ...   \n",
       "\n",
       "   vases_lidar8  vases_lidar9  vases_lidar10  vases_lidar11  vases_lidar12  \\\n",
       "0      0.000000      0.000000       0.000000            0.0            0.0   \n",
       "1      0.492113      0.629606       0.137120            0.0            0.0   \n",
       "2      0.210128      0.780801       0.570618            0.0            0.0   \n",
       "3      0.666369      0.682326       0.015416            0.0            0.0   \n",
       "4      0.000000      0.000000       0.000000            0.0            0.0   \n",
       "\n",
       "   vases_lidar13  vases_lidar14  vases_lidar15   action0   action1  \n",
       "0            0.0            0.0            0.0  0.338574  0.490314  \n",
       "1            0.0            0.0            0.0  0.424049  0.655643  \n",
       "2            0.0            0.0            0.0  0.514721  0.687201  \n",
       "3            0.0            0.0            0.0  0.442407  0.292759  \n",
       "4            0.0            0.0            0.0  0.483764  0.500775  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data with MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler((0,1))\n",
    "scaled = scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled, columns=obs_column_names)\n",
    "scaled_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01721909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accelerometer0</th>\n",
       "      <th>accelerometer1</th>\n",
       "      <th>velocimeter0</th>\n",
       "      <th>velocimeter1</th>\n",
       "      <th>gyro2</th>\n",
       "      <th>magnetometer0</th>\n",
       "      <th>magnetometer1</th>\n",
       "      <th>goal_lidar0</th>\n",
       "      <th>goal_lidar1</th>\n",
       "      <th>goal_lidar2</th>\n",
       "      <th>...</th>\n",
       "      <th>vases_lidar8</th>\n",
       "      <th>vases_lidar9</th>\n",
       "      <th>vases_lidar10</th>\n",
       "      <th>vases_lidar11</th>\n",
       "      <th>vases_lidar12</th>\n",
       "      <th>vases_lidar13</th>\n",
       "      <th>vases_lidar14</th>\n",
       "      <th>vases_lidar15</th>\n",
       "      <th>action0</th>\n",
       "      <th>action1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.511091</td>\n",
       "      <td>0.500032</td>\n",
       "      <td>0.507938</td>\n",
       "      <td>0.507288</td>\n",
       "      <td>0.500896</td>\n",
       "      <td>0.499463</td>\n",
       "      <td>0.500887</td>\n",
       "      <td>0.056146</td>\n",
       "      <td>0.056738</td>\n",
       "      <td>0.056568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056717</td>\n",
       "      <td>0.057083</td>\n",
       "      <td>0.057048</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.056875</td>\n",
       "      <td>0.056385</td>\n",
       "      <td>0.057626</td>\n",
       "      <td>0.058439</td>\n",
       "      <td>0.435692</td>\n",
       "      <td>0.485823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.178317</td>\n",
       "      <td>0.168458</td>\n",
       "      <td>0.239512</td>\n",
       "      <td>0.270450</td>\n",
       "      <td>0.390636</td>\n",
       "      <td>0.352747</td>\n",
       "      <td>0.354360</td>\n",
       "      <td>0.158660</td>\n",
       "      <td>0.160283</td>\n",
       "      <td>0.160234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161911</td>\n",
       "      <td>0.162817</td>\n",
       "      <td>0.162562</td>\n",
       "      <td>0.162641</td>\n",
       "      <td>0.161846</td>\n",
       "      <td>0.161016</td>\n",
       "      <td>0.164293</td>\n",
       "      <td>0.166853</td>\n",
       "      <td>0.083307</td>\n",
       "      <td>0.121575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.330737</td>\n",
       "      <td>0.463165</td>\n",
       "      <td>0.348918</td>\n",
       "      <td>0.207115</td>\n",
       "      <td>0.036675</td>\n",
       "      <td>0.148050</td>\n",
       "      <td>0.146654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382385</td>\n",
       "      <td>0.387084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.506868</td>\n",
       "      <td>0.499687</td>\n",
       "      <td>0.506761</td>\n",
       "      <td>0.507630</td>\n",
       "      <td>0.503268</td>\n",
       "      <td>0.498098</td>\n",
       "      <td>0.501473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436136</td>\n",
       "      <td>0.485807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.695346</td>\n",
       "      <td>0.536827</td>\n",
       "      <td>0.668312</td>\n",
       "      <td>0.805708</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.852273</td>\n",
       "      <td>0.856394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.488516</td>\n",
       "      <td>0.583831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accelerometer0  accelerometer1   velocimeter0   velocimeter1  \\\n",
       "count   100000.000000   100000.000000  100000.000000  100000.000000   \n",
       "mean         0.511091        0.500032       0.507938       0.507288   \n",
       "std          0.178317        0.168458       0.239512       0.270450   \n",
       "min          0.000000        0.000000       0.000000       0.000000   \n",
       "25%          0.330737        0.463165       0.348918       0.207115   \n",
       "50%          0.506868        0.499687       0.506761       0.507630   \n",
       "75%          0.695346        0.536827       0.668312       0.805708   \n",
       "max          1.000000        1.000000       1.000000       1.000000   \n",
       "\n",
       "               gyro2  magnetometer0  magnetometer1    goal_lidar0  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.500896       0.499463       0.500887       0.056146   \n",
       "std         0.390636       0.352747       0.354360       0.158660   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.036675       0.148050       0.146654       0.000000   \n",
       "50%         0.503268       0.498098       0.501473       0.000000   \n",
       "75%         0.961934       0.852273       0.856394       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         goal_lidar1    goal_lidar2  ...   vases_lidar8   vases_lidar9  \\\n",
       "count  100000.000000  100000.000000  ...  100000.000000  100000.000000   \n",
       "mean        0.056738       0.056568  ...       0.056717       0.057083   \n",
       "std         0.160283       0.160234  ...       0.161911       0.162817   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "       vases_lidar10  vases_lidar11  vases_lidar12  vases_lidar13  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.057048       0.057200       0.056875       0.056385   \n",
       "std         0.162562       0.162641       0.161846       0.161016   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       vases_lidar14  vases_lidar15        action0        action1  \n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000  \n",
       "mean        0.057626       0.058439       0.435692       0.485823  \n",
       "std         0.164293       0.166853       0.083307       0.121575  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.382385       0.387084  \n",
       "50%         0.000000       0.000000       0.436136       0.485807  \n",
       "75%         0.000000       0.000000       0.488516       0.583831  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a291327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into train, test and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2)\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ac6679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64000, 57)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8962d62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 57)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5044348c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 57)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b84b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert dataset into a TensorDataset\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train.values.astype(np.float32)), torch.from_numpy(y_train.values.astype(np.float32)))\n",
    "validation_dataset = TensorDataset(torch.from_numpy(X_validate.values.astype(np.float32)), torch.from_numpy(y_validate.values.astype(np.float32)))\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test.values.astype(np.float32)), torch.from_numpy(y_test.values.astype(np.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e80ac757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Putting data into dataloaders for PyTorch\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0b8f0",
   "metadata": {},
   "source": [
    "# Building a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3a65ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExpectedCostNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpectedCostNN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(57, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aedcf2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04de692d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpectedCostNN(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=57, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ExpectedCostNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89d2a8",
   "metadata": {},
   "source": [
    "# Training a neural network on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e518cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c154aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8886a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted to regression problem from original code https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf9c7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/bachelor/RL/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/user/bachelor/RL/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 377.963227 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Avg loss: 377.823396 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Avg loss: 377.758091 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Avg loss: 377.382269 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Avg loss: 377.335206 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Avg loss: 377.428332 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Avg loss: 377.970975 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Avg loss: 377.360335 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Avg loss: 378.587842 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Avg loss: 377.252595 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# code from https://docs.pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9200e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model, \"simple_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43ee90",
   "metadata": {},
   "source": [
    "# Evaluation of the model / Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45e0939",
   "metadata": {},
   "source": [
    "exp_cost has a mean of 9.91 and standard deviation of 19.74.\n",
    "That means an acceptal model should have produce a MSE lower much lower than 390 which is the variance of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722aaef0",
   "metadata": {},
   "source": [
    "1. Comparing optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7abe7f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\"SGD\": torch.optim.SGD(model.parameters(), lr=1e-3),\n",
    "              \"RMSProp\": torch.optim.RMSprop(model.parameters(), lr=1e-3),\n",
    "              \"Adam\": torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f774f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD:\n",
      "-------------------------------\n",
      "Avg loss: 399.143951 \n",
      "\n",
      "R^2 Score: -0.000251\n"
     ]
    }
   ],
   "source": [
    "# SGD\n",
    "model_sgd = ExpectedCostNN().to(device)\n",
    "sgd = torch.optim.SGD(model_sgd.parameters(), lr=1e-3)\n",
    "for _ in range(10):\n",
    "    train(train_loader, model_sgd, loss_fn, sgd)\n",
    "print(\"SGD:\\n-------------------------------\")\n",
    "mse_score = test(validation_loader, model_sgd, loss_fn)\n",
    "print(f\"R^2 Score: {1-mse_score/np.var(y_validate):>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28886a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD:\n",
      "-------------------------------\n",
      "Avg loss: 399.220341 \n",
      "\n",
      "R^2 Score: -0.000442\n"
     ]
    }
   ],
   "source": [
    "# RMSProp\n",
    "model_rms = ExpectedCostNN().to(device)\n",
    "rms = torch.optim.RMSprop(model_rms.parameters(), lr=1e-3)\n",
    "for _ in range(10):\n",
    "    train(train_loader, model_rms, loss_fn, rms)\n",
    "print(\"RMSProp:\\n-------------------------------\")\n",
    "mse_score = test(validation_loader, model_rms, loss_fn)\n",
    "print(f\"R^2 Score: {1-mse_score/np.var(y_validate):>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd6e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD:\n",
      "-------------------------------\n",
      "Avg loss: 399.079756 \n",
      "\n",
      "R^2 Score: -0.000090\n"
     ]
    }
   ],
   "source": [
    "# ADAM\n",
    "model_adam = ExpectedCostNN().to(device)\n",
    "adam = torch.optim.SGD(model_adam.parameters(), lr=1e-3)\n",
    "for _ in range(10):\n",
    "    train(train_loader, model_adam, loss_fn, adam)\n",
    "print(\"Adam:\\n-------------------------------\")\n",
    "mse_score = test(validation_loader, model_adam, loss_fn)\n",
    "print(f\"R^2 Score: {1-mse_score/np.var(y_validate):>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4deab",
   "metadata": {},
   "source": [
    "2. Trying out different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5787daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/bachelor/RL/lib/python3.8/site-packages/torch/nn/modules/loss.py:538: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate 0.0001:\n",
      "-------------------------------\n",
      "Avg loss: 399.062979 \n",
      "\n",
      "R^2 Score: -0.000048\n",
      "Learning rate 0.002575:\n",
      "-------------------------------\n",
      "Avg loss: 400.825031 \n",
      "\n",
      "R^2 Score: -0.004463\n",
      "Learning rate 0.005050000000000001:\n",
      "-------------------------------\n",
      "Avg loss: 399.033265 \n",
      "\n",
      "R^2 Score: 0.000027\n",
      "Learning rate 0.007525000000000001:\n",
      "-------------------------------\n",
      "Avg loss: 399.034968 \n",
      "\n",
      "R^2 Score: 0.000022\n",
      "Learning rate 0.01:\n",
      "-------------------------------\n",
      "Avg loss: 399.041231 \n",
      "\n",
      "R^2 Score: 0.000007\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.linspace(1e-4, 1e-2, 5)\n",
    "for lr in learning_rates:\n",
    "    model = ExpectedCostNN().to(device)\n",
    "    adam = torch.optim.SGD(model_adam.parameters(), lr=lr)\n",
    "    for _ in range(10):\n",
    "        train(train_loader, model_adam, loss_fn, adam)\n",
    "    print(f\"Learning rate {lr}:\\n-------------------------------\")\n",
    "    mse_score = test(validation_loader, model_adam, loss_fn)\n",
    "    print(f\"R^2 Score: {1-mse_score/np.var(y_validate):>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7234f",
   "metadata": {},
   "source": [
    "3. Determining a good model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ec5ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExpectedCostNN(nn.Module):\n",
    "    def __init__(self, hidden_layers):\n",
    "        super(ExpectedCostNN, self).__init__()\n",
    "        self.layers = hidden_layers\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582da531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(amount, size, epochs=5):\n",
    "    layers = [nn.Linear(57, size), nn.ReLU()]\n",
    "    for _ in range(amount):\n",
    "        layers.append(nn.Linear(size, size))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(size,1))\n",
    "    model = ExpectedCostNN(nn.Sequential(*layers)).to(device)\n",
    "    optimizer = torch.optim.adam(model.parameters(), lr=1e-3)\n",
    "    for t in range(epochs):\n",
    "        train(train_loader, model, loss_fn, optimizer)\n",
    "    print(f\"{amount} * {size}:\\n-------------------------------\")\n",
    "    test(test_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77840c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 * 32:\n",
      "-------------------------------\n",
      "Avg loss: 400.265770 \n",
      "\n",
      "1 * 64:\n",
      "-------------------------------\n",
      "Avg loss: 399.005155 \n",
      "\n",
      "1 * 128:\n",
      "-------------------------------\n",
      "Avg loss: 398.130220 \n",
      "\n",
      "1 * 256:\n",
      "-------------------------------\n",
      "Avg loss: 398.217007 \n",
      "\n",
      "2 * 32:\n",
      "-------------------------------\n",
      "Avg loss: 398.054952 \n",
      "\n",
      "2 * 64:\n",
      "-------------------------------\n",
      "Avg loss: 398.035413 \n",
      "\n",
      "2 * 128:\n",
      "-------------------------------\n",
      "Avg loss: 398.008653 \n",
      "\n",
      "2 * 256:\n",
      "-------------------------------\n",
      "Avg loss: 398.154671 \n",
      "\n",
      "3 * 32:\n",
      "-------------------------------\n",
      "Avg loss: 398.608153 \n",
      "\n",
      "3 * 64:\n",
      "-------------------------------\n",
      "Avg loss: 400.134154 \n",
      "\n",
      "3 * 128:\n",
      "-------------------------------\n",
      "Avg loss: 398.012474 \n",
      "\n",
      "3 * 256:\n",
      "-------------------------------\n",
      "Avg loss: 398.006742 \n",
      "\n",
      "4 * 32:\n",
      "-------------------------------\n",
      "Avg loss: 398.285077 \n",
      "\n",
      "4 * 64:\n",
      "-------------------------------\n",
      "Avg loss: 398.019244 \n",
      "\n",
      "4 * 128:\n",
      "-------------------------------\n",
      "Avg loss: 398.011666 \n",
      "\n",
      "4 * 256:\n",
      "-------------------------------\n",
      "Avg loss: 398.025186 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_sizes = [32, 64, 128, 256]\n",
    "hidden_layer_amounts = [1, 2, 3, 4]\n",
    "\n",
    "for i in hidden_layer_amounts:\n",
    "    for j in hidden_layer_sizes:\n",
    "        train_and_eval(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
